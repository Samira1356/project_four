{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /opt/conda/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = pg2.connect(host='postgres',\n",
    "                         user='postgres',\n",
    "                         database='postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    con = pg2.connect(host='postgres', \n",
    "                      dbname='postgres', \n",
    "                      user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    return con, cur\n",
    "\n",
    "\n",
    "#creates a connection and a cursor\n",
    "#uses the cursor to execute a query\n",
    "#if fetch_res is True it fetches the results, otherwise results are None\n",
    "#closes the connection and returns results\n",
    "def query_to_dictionary(query, fetch_res=True):\n",
    "    con, cur = connect_to_db()\n",
    "    cur.execute(query)\n",
    "    if fetch_res:\n",
    "        results = cur.fetchall()\n",
    "    else:\n",
    "        results = None\n",
    "    con.close()\n",
    "    return results\n",
    "\n",
    "def query_to_dataframe(query):\n",
    "    return DataFrame(query_to_dictionary(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business software</td>\n",
       "      <td>Business_Software</td>\n",
       "      <td>1037763</td>\n",
       "      <td>Business software or a business application is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AccuSystems</td>\n",
       "      <td>Business_Software</td>\n",
       "      <td>41270069</td>\n",
       "      <td>AccuSystems LLC is an American company headqua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Active policy management</td>\n",
       "      <td>Business_Software</td>\n",
       "      <td>5211212</td>\n",
       "      <td>Active policy management is business-oriented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexandria (library software)</td>\n",
       "      <td>Business_Software</td>\n",
       "      <td>28502793</td>\n",
       "      <td>Alexandria is browser based cross-platform lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alteryx</td>\n",
       "      <td>Business_Software</td>\n",
       "      <td>44133735</td>\n",
       "      <td>Alteryx is an American computer software compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        category            content    pageid  \\\n",
       "0              Business software  Business_Software   1037763   \n",
       "1                    AccuSystems  Business_Software  41270069   \n",
       "2       Active policy management  Business_Software   5211212   \n",
       "3  Alexandria (library software)  Business_Software  28502793   \n",
       "4                        Alteryx  Business_Software  44133735   \n",
       "\n",
       "                                               title  \n",
       "0  Business software or a business application is...  \n",
       "1  AccuSystems LLC is an American company headqua...  \n",
       "2  Active policy management is business-oriented ...  \n",
       "3  Alexandria is browser based cross-platform lib...  \n",
       "4  Alteryx is an American computer software compa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_to_dataframe('SELECT * FROM contents LIMIT 5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_q_df = query_to_dataframe(\"\"\"\n",
    "    SELECT category as title, content as category, pageid, title as content\n",
    "    FROM contents\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Business software or a business application is...</td>\n",
       "      <td>1037763</td>\n",
       "      <td>Business software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>AccuSystems LLC is an American company headqua...</td>\n",
       "      <td>41270069</td>\n",
       "      <td>AccuSystems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Active policy management is business-oriented ...</td>\n",
       "      <td>5211212</td>\n",
       "      <td>Active policy management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Alexandria is browser based cross-platform lib...</td>\n",
       "      <td>28502793</td>\n",
       "      <td>Alexandria (library software)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Alteryx is an American computer software compa...</td>\n",
       "      <td>44133735</td>\n",
       "      <td>Alteryx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category                                            content  \\\n",
       "0  Business_Software  Business software or a business application is...   \n",
       "1  Business_Software  AccuSystems LLC is an American company headqua...   \n",
       "2  Business_Software  Active policy management is business-oriented ...   \n",
       "3  Business_Software  Alexandria is browser based cross-platform lib...   \n",
       "4  Business_Software  Alteryx is an American computer software compa...   \n",
       "\n",
       "     pageid                          title  \n",
       "0   1037763              Business software  \n",
       "1  41270069                    AccuSystems  \n",
       "2   5211212       Active policy management  \n",
       "3  28502793  Alexandria (library software)  \n",
       "4  44133735                        Alteryx  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4130, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oracle Fusion Middleware</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OJB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon (program)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koru search engine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Local case-control sampling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Structured sparsity regularization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Restaurant Bigwig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Application sharing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>List of content management systems</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Truncation selection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trading room</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Intraboom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Uniform convergence in probability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Free and open-source ATS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Houthoff Buruma The Game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Beaver Group</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bradley–Terry model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TeamDrive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Teuvo Kohonen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Get Satisfaction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LIBSVM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Message-oriented middleware</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Parallel metaheuristic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Oracle Data Mining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Accessaphone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Knolskape</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Feature extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Headstart (company)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AEX cfiXML</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>Workplace by Facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>Jacada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>Citrix Receiver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>Nota Bene (word processor)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>ObjectSecurity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>Talygen Business Intelligence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>Java API for RESTful Web Services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>Ability Plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>Internet Messaging Program</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>Multiplan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>MindWrite</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>Apache Kylin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>Gaussian process</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>Black Gold (video game)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>Data Recall Diamond</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>IBM Administrative Terminal System</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>Mobile Associate Communication Platform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>Symphony Communication</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>Nonlinear dimensionality reduction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>Mpedigree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>Komprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>Oracle Application Server</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>Neuroevolution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>Lotus Manuscript</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>Mezzanine (CMS)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>Sage Group</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>Web2project</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>IBM Lotus Symphony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>Parasoft Concerto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>Pandoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     category  count\n",
       "0                    Oracle Fusion Middleware      1\n",
       "1                                         OJB      1\n",
       "2                           Lexicon (program)      1\n",
       "3                          Koru search engine      1\n",
       "4                 Local case-control sampling      1\n",
       "5          Structured sparsity regularization      1\n",
       "6                           Restaurant Bigwig      1\n",
       "7                         Application sharing      1\n",
       "8          List of content management systems      1\n",
       "9                        Truncation selection      1\n",
       "10                               Trading room      1\n",
       "11                                  Intraboom      1\n",
       "12         Uniform convergence in probability      1\n",
       "13                   Free and open-source ATS      1\n",
       "14                   Houthoff Buruma The Game      1\n",
       "15                                  Andrew Ng      1\n",
       "16                               Beaver Group      1\n",
       "17                        Bradley–Terry model      1\n",
       "18                                  TeamDrive      1\n",
       "19                              Teuvo Kohonen      1\n",
       "20                           Get Satisfaction      1\n",
       "21                                     LIBSVM      1\n",
       "22                Message-oriented middleware      1\n",
       "23                     Parallel metaheuristic      1\n",
       "24                         Oracle Data Mining      1\n",
       "25                               Accessaphone      1\n",
       "26                                  Knolskape      1\n",
       "27                         Feature extraction      1\n",
       "28                        Headstart (company)      1\n",
       "29                                 AEX cfiXML      1\n",
       "...                                       ...    ...\n",
       "4093                    Workplace by Facebook      1\n",
       "4094                                   Jacada      1\n",
       "4095                          Citrix Receiver      1\n",
       "4096               Nota Bene (word processor)      1\n",
       "4097                           ObjectSecurity      1\n",
       "4098            Talygen Business Intelligence      1\n",
       "4099        Java API for RESTful Web Services      1\n",
       "4100                             Ability Plus      1\n",
       "4101               Internet Messaging Program      1\n",
       "4102                                Multiplan      1\n",
       "4103                                MindWrite      1\n",
       "4104                             Apache Kylin      1\n",
       "4105                         Gaussian process      1\n",
       "4106                  Black Gold (video game)      1\n",
       "4107                      Data Recall Diamond      1\n",
       "4108       IBM Administrative Terminal System      1\n",
       "4109  Mobile Associate Communication Platform      1\n",
       "4110                   Symphony Communication      1\n",
       "4111       Nonlinear dimensionality reduction      1\n",
       "4112                                Mpedigree      1\n",
       "4113                                 Komprise      1\n",
       "4114                Oracle Application Server      1\n",
       "4115                           Neuroevolution      1\n",
       "4116                         Lotus Manuscript      1\n",
       "4117                          Mezzanine (CMS)      1\n",
       "4118                               Sage Group      1\n",
       "4119                              Web2project      1\n",
       "4120                       IBM Lotus Symphony      1\n",
       "4121                        Parasoft Concerto      1\n",
       "4122                                   Pandoc      1\n",
       "\n",
       "[4123 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT category, COUNT( title) FROM contents GROUP BY category;\"\"\"\n",
    "query = re.sub( '\\s+', \" \", query)\n",
    "query_to_dataframe( query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT * FROM ( (SELECT pageid, title FROM contents WHERE category = 'Business_Software') as BS INNER JOIN (SELECT pageid, title FROM contents WHERE category = 'Machine_Learning' ) as ML ON bs.pageid = ML.pageid ) stuff;\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT * \n",
    "FROM\n",
    "( (SELECT pageid, title FROM contents WHERE category = 'Business_Software') as BS \n",
    "INNER JOIN \n",
    "(SELECT pageid, title FROM contents WHERE category = 'Machine_Learning' ) as ML\n",
    "ON bs.pageid = ML.pageid\n",
    ") stuff;\"\"\"\n",
    "\n",
    "query = re.sub( '\\s+', \" \", query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_to_dataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4130 entries, 0 to 4129\n",
      "Data columns (total 4 columns):\n",
      "category    4130 non-null object\n",
      "content     4115 non-null object\n",
      "pageid      4130 non-null int64\n",
      "title       4130 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 129.1+ KB\n"
     ]
    }
   ],
   "source": [
    "content_q_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category     0\n",
       "content     15\n",
       "pageid       0\n",
       "title        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_q_df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "content     0\n",
       "pageid      0\n",
       "title       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Business software or a business application is any software or set of computer programs used by business users to perform various business functions. These business applications are used to increase productivity, to measure productivity and to perform other business functions accurately.\\nBy and large, business software is likely to be developed to meet the needs of a specific business, and therefore is not easily transferable to a different business environment, unless its nature and operation is identical. Due to the unique requirements of each business, off-the-shelf software is unlikely to completely address a company's needs. However, where an on-the-shelf solution is necessary, due to time or monetary considerations, some level of customization is likely to be required. Exceptions do exist, depending on the business in question, and thorough research is always required before committing to bespoke or off-the-shelf solutions.\\nSome business applications are interactive, i.e., they have a graphical user interface or user interface and users can query/modify/input data and view results instantaneously. They can also run reports instantaneously. Some business applications run in batch mode: they are set up to run based on a predetermined event/time and a business user does not need to initiate them or monitor them.\\nSome business applications are built in-house and some are bought from vendors (off the shelf software products). These business applications are installed on either desktops or big servers. Prior to the introduction of COBOL (a universal compiler) in 1965, businesses developed their own unique machine language. RCA's language consisted of a 12-position instruction. For example, to read a record into memory, the first two digits would be the instruction (action) code. The next four positions of the instruction (an 'A' address) would be the exact leftmost memory location where you want the readable character to be placed. Four positions (a 'B' address) of the instruction would note the very rightmost memory location where you want the last character of the record to be located. A two digit 'B' address also allows a modification of any instruction. Instruction codes and memory designations excluded the use of 8's or 9's. The first RCA business application was implemented in 1962 on a 4k RCA 301. The RCA 301, mid frame 501, and large frame 601 began their marketing in early 1960.\\nMany kinds of users are found within the business environment, and can be categorized by using a small, medium and large matrix:\\nThe small business market generally consists of home accounting software, and office suites such as OpenOffice.org or Microsoft Office.\\nThe medium size, or small and medium-sized enterprise (SME), has a broader range of software applications, ranging from accounting, groupware, customer relationship management, human resource management systems, outsourcing relationship management, loan origination software, shopping cart software, field service software, and other productivity enhancing applications.\\nThe last segment covers enterprise level software applications, such as those in the fields of enterprise resource planning, enterprise content management (ECM), business process management (BPM) and product lifecycle management. These applications are extensive in scope, and often come with modules that either add native functions, or incorporate the functionality of third-party computer programs.\\nTechnologies that previously only existed in peer-to-peer software applications, like Kazaa and Napster, are starting to appear within business applications.\\n\\n\\n== Types of business tools ==\\nEnterprise application software (EAS)\\nResource Management\\nDigital dashboards, also known as business intelligence dashboards, enterprise dashboards, or executive dashboards. These are visually based summaries of business data that show at-a-glance understanding of conditions through metrics and key performance indicators (KPIs). Dashboards are a very popular tools that have arisen in the last few years.\\nOnline analytical processing (OLAP), (which include HOLAP, ROLAP and MOLAP) - are a capability of some management, decision support, and executive information systems that support interactive examination of large amounts of data from many perspectives.\\nReporting software generates aggregated views of data to keep the management informed about the state of their business.\\nProcurement software is business software that helps to automate the purchasing function of organizations.\\nData mining is the extraction of consumer information from a database by utilizing software that can isolate and identify previously unknown patterns or trends in large amounts of data. There is a variety of data mining techniques that reveal different types of patterns. Some of the techniques that belong here are statistical methods (particularly business statistics) and neural networks, as very advanced means of analyzing data.\\nBusiness performance management (BPM)\\nDocument management software is made for organizing and managing multiple documents of various types. Some of them have storage functions for security and back-up of valuable business information.\\nEmployee scheduling software- used for creating and distributing employee schedules, as well as for tracking employee hours.\\n\\n\\n== Brief history ==\\nThe essential motivation for business software is to increase profits by cutting costs or speeding the productive cycle. In the earliest days of white-collar business automation, large mainframe computers were used to tackle the most tedious jobs, like bank cheque clearing and factory accounting.\\nFactory accounting software was among the most popular of early business software tools, and included the automation of general ledgers, fixed assets inventory ledgers, cost accounting ledgers, accounts receivable ledgers, and accounts payable ledgers (including payroll, life insurance, health insurance, federal and state insurance and retirement).\\nThe early use of software to replace manual white-collar labor was extremely profitable, and caused a radical shift in white-collar labor. One computer might easily replace 100 white-collar 'pencil pushers', and the computer would not require any health or retirement benefits.\\nBuilding on these early successes with IBM, Hewlett-Packard and other early suppliers of business software solutions, corporate consumers demanded business software to replace the old-fashioned drafting board. CAD-CAM software (or computer-aided drafting for computer-aided manufacturing) arrived in the early 1980s. Also, project management software was so valued in the early 1980s that it might cost as much as $500,000 per copy (although such software typically had far fewer capabilities than modern project management software such as Microsoft Project, which one might purchase today for under $500 per copy.)\\nIn the early days, perhaps the most noticeable, widespread change in business software was the word processor. Because of its rapid rise, the ubiquitous IBM typewriter suddenly vanished in the 1980s as millions of companies worldwide shifted to the use of Word Perfect business software, and later, Microsoft Word software. Another vastly popular computer program for business were mathematical spreadsheet programs such as Lotus 1-2-3, and later Microsoft Excel.\\nIn the 1990s business shifted massively towards globalism with the appearance of SAP software which coordinates a supply-chain of vendors, potentially worldwide, for the most efficient, streamlined operation of factory manufacture.\\nYet nothing in the history of business software has had the global impact of the Internet, with its email and websites that now serve commercial interests worldwide. Globalism in business fully arrived when the Internet became a household word.\\nThe next phase in the evolution of business software is being led by the emergance of Robotic Process Automation (RPA), which involves identifying and automating highly repetitive tasks and processes, with an aim to drive operational efficiency, reduce costs and limit human error. Industries that have been in the forefront of RPA adoption include the Insurance industry, Banking and Financial Services, the Legal industry and the Healthcare industry.\\n\\n\\n== Application support ==\\nBusiness applications are built based on the requirements from the business users. Also, these business applications are built to use certain kind of Business transactions or data items. These business applications run flawlessly until there are no new business requirements or there is no change in underlying Business transactions. Also, the business applications run flawlessly if there are no issues with computer hardware, computer networks (Intenet/intranet), computer disks, power supplies, and various software components (middleware, database, computer programs, etc.).\\nBusiness applications can fail when an unexpected error occurs. This error could occur due to a data error (an unexpected data input or a wrong data input), an environment error (an in frastructure related error), a programming error, a human error or a work flow error. When a business application fails one needs to fix the business application error as soon as possible so that the business users can resume their work. This work of resolving business application errors is known as business application support.\\n\\n\\n=== Reporting errors ===\\nThe Business User calls the business application support team phone number or sends an e-mail to the business application support team. The business application support team gets all the details of the error from the business user on the phone or from the e-mail. These details are then entered in a tracking software. The tracking software creates a request number and this request number is given to the business user. This request number is used to track the progress on the support issue. The request is assigned to a support team member.\\n\\n\\n=== Notification of errors ===\\nFor critical business application errors (such as an application not available or an application not working correctly), an e-mail is sent to the entire organization or impacted teams so that they are aware of the issue. They are also provided with an estimated time for application availability.\\n\\n\\n=== Investigation or analysis of application errors ===\\nThe business application support team member collects all the necessary information about the business software error. This information is then recorded in the support request. All of the data used by the business user is also used in the investigation. The application program is reviewed for any possible programming errors.\\n\\n\\n=== Error resolution ===\\nIf any similar business application errors occurred in the past then the issue resolution steps are retrieved from the support knowledge base and the error is resolved using those steps. If it is a new support error, then new issue resolution steps are created and the error is resolved. The new support error resolution steps are recorded in the knowledge base for future use. For major business application errors (critical infrastructure or application failures), a phone conference call is initiated and all required support persons/teams join the call and they all work together to resolve the error.\\n\\n\\n=== Code correction ===\\nIf the business application error occurred due to programming errors, then a request is created for the application development team to correct programming errors. If the business user needs new features or functions in the business application, then the required analysis/design/programming/testing/release is planned and a new version of the business software is deployed.\\n\\n\\n=== Business process correction ===\\nIf the business application error occurred due to a work flow issue or human errors during data input, then the business users are notified. Business users then review their work flow and revise it if necessary. They also modify the user guide or user instructions to avoid such an error in the future.\\n\\n\\n=== Infrastructure issue correction ===\\nIf the business application error occurred due to infrastructure issues, then the specific infrastructure team is notified. The infrastructure team then implements permanent fixes for the issue and monitors the infrastructure to avoid the re-occurrence of the same error.\\n\\n\\n== Support follow up and internal reporting ==\\nThe business application error tracking system is used to review all issues periodically (daily, weekly and monthly) and reports are generated to monitor the resolved issues, repeating issues, and pending issues. Reports are also generated for the IT/IS management for improvement and management of business applications.\\n\\n\\n== See also ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.content.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'In statistics, \\'Markov chain Monte Carlo\\' (MCMC) methods are a class of algorithms for sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its equilibrium distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.\\n\\nRandom walk Monte Carlo methods make up a large subclass of MCMC methods.\\n\\n\\n== Application domains ==\\nMCMC methods are primarily used for calculating numerical approximations of multi-dimensional integrals, for example in Bayesian statistics, computational physics, computational biology and computational linguistics.\\nIn Bayesian statistics, the recent development of MCMC methods has been a key step in making it possible to compute large hierarchical models that require integrations over hundreds or even thousands of unknown parameters.\\nThey are also used for generating samples that gradually populate the rare failure region in rare event sampling.\\n\\n\\n== Classification ==\\n\\n\\n=== Random walk Monte Carlo methods ===\\n\\n\\n==== Multi-dimensional integrals ====\\nWhen an MCMC method is used for approximating a multi-dimensional integral, an ensemble of \"walkers\" move around randomly. At each point where a walker steps, the integrand value at that point is counted towards the integral. The walker then may make a number of tentative steps around the area, looking for a place with a reasonably high contribution to the integral to move into next.\\nRandom walk Monte Carlo methods are a kind of random simulation or Monte Carlo method. However, whereas the random samples of the integrand used in a conventional Monte Carlo integration are statistically independent, those used in MCMC methods are correlated. A Markov chain is constructed in such a way as to have the integrand as its equilibrium distribution.\\n\\n\\n==== Examples ====\\nExamples of random walk Monte Carlo methods include the following:\\nMetropolis–Hastings algorithm: This method generates a random walk using a proposal density and a method for rejecting some of the proposed moves.\\nGibbs sampling: This method requires all the conditional distributions of the target distribution to be sampled exactly. When drawing from the full-conditional distributions is not straightforward other samplers-within-Gibbs are used (e.g., see ). Gibbs sampling is popular partly because it does not require any \\'tuning\\'.\\nSlice sampling: This method depends on the principle that one can sample from a distribution by sampling uniformly from the region under the plot of its density function. It alternates uniform sampling in the vertical direction with uniform sampling from the horizontal \\'slice\\' defined by the current vertical position.\\nMultiple-try Metropolis: This method is a variation of the Metropolis–Hastings algorithm that allows multiple trials at each point. By making it possible to take larger steps at each iteration, it helps address the curse of dimensionality.\\nReversible-jump: This method is a variant of the Metropolis–Hastings algorithm that allows proposals that change the dimensionality of the space. MCMC methods that change dimensionality have long been used in statistical physics applications, where for some problems a distribution that is a grand canonical ensemble is used (e.g., when the number of molecules in a box is variable). But the reversible-jump variant is useful when doing MCMC or Gibbs sampling over nonparametric Bayesian models such as those involving the Dirichlet process or Chinese restaurant process, where the number of mixing components/clusters/etc. is automatically inferred from the data.\\n\\n\\n=== Other MCMC methods ===\\n\\n\\n==== Training-based MCMC ====\\nUnlike most of the current MCMC methods that ignore the previous trials, using a new algorithm the MCMC algorithm is able to use the previous steps and generate the next candidate. This training-based algorithm is able to speed-up the MCMC algorithm by an order of magnitude.\\nInteracting MCMC methodologies are a class of mean field particle methods for obtaining random samples from a sequence of probability distributions with an increasing level of sampling complexity. These probabilistic models include path space state models with increasing time horizon, posterior distributions w.r.t. sequence of partial observations, increasing constraint level sets for conditional distributions, decreasing temperature schedules associated with some Boltzmann-Gibbs distributions, and many others. In principle, any MCMC sampler can be turned into an interacting MCMC sampler. These interacting MCMC samplers can be interpreted as a way to run in parallel a sequence of MCMC samplers. For instance, interacting simulated annealing algorithms are based on independent Metropolis-Hastings moves interacting sequentially with a selection-resampling type mechanism. In contrast to traditional MCMC methods, the precision parameter of this class of interacting MCMC samplers is only related to the number of interacting MCMC samplers. These advanced particle methodologies belong to the class of Feynman-Kac particle models, also called Sequential Monte Carlo or particle filter methods in Bayesian inference and signal processing communities. Interacting MCMC methods can also be interpreted as a mutation-selection genetic particle algorithm with MCMC mutations.\\nMarkov Chain quasi-Monte Carlo (MCQMC) The advantage of low-discrepancy sequences in lieu of random numbers for simple independent Monte Carlo sampling is well known. This procedure, known as Quasi-Monte Carlo method (QMC), yields an integration error that decays at a superior rate to that obtained by IID sampling, by the Koksma-Hlawka inequality. Empirically it allows the reduction of both estimation error and convergence time by an order of magnitude.\\n\\n\\n==== Reducing correlation ====\\nMore sophisticated methods use various ways of reducing the correlation between successive samples. These algorithms may be harder to implement, but they usually exhibit faster convergence (i.e. fewer steps for an accurate result).\\n\\n\\n==== Examples ====\\nExamples of non-random walk MCMC methods include the following:\\nHybrid Monte Carlo (HMC): Tries to avoid random walk behaviour by introducing an auxiliary momentum vector and implementing Hamiltonian dynamics, so the potential energy function is the target density. The momentum samples are discarded after sampling. The end result of Hybrid Monte Carlo is that proposals move across the sample space in larger steps; they are therefore less correlated and converge to the target distribution more rapidly.\\nSome variations on slice sampling also avoid random walks.\\nLangevin MCMC and other methods that rely on the gradient (and possibly second derivative) of the log posterior avoid random walks by making proposals that are more likely to be in the direction of higher probability density.\\n\\n\\n== Convergence ==\\nUsually it is not hard to construct a Markov chain with the desired properties. The more difficult problem is to determine how many steps are needed to converge to the stationary distribution within an acceptable error. A good chain will have rapid mixing: the stationary distribution is reached quickly starting from an arbitrary position. A standard empirical method to assess convergence is to run several independent simulated Markov chains and check that the ratio of inter-chain to intra-chain variances for all the parameters sampled is close to 1.\\nTypically, MCMC sampling can only approximate the target distribution, as there is always some residual effect of the starting position. More sophisticated MCMC-based algorithms such as coupling from the past can produce exact samples, at the cost of additional computation and an unbounded (though finite in expectation) running time.\\nMany random walk Monte Carlo methods move around the equilibrium distribution in relatively small steps, with no tendency for the steps to proceed in the same direction. These methods are easy to implement and analyze, but unfortunately it can take a long time for the walker to explore all of the space. The walker will often double back and cover ground already covered.\\n\\n\\n== See also ==\\n\\n\\n== Sources ==\\n\\n\\n== Further reading ==\\n\\n\\n== Software ==\\nSeveral software programs provide MCMC sampling capabilities, for example:\\nBUGS / WinBUGS\\nJAGS\\nMCSim\\nR (programming language) with the packages adaptMCMC, atmcmc, BRugs, mcmc, MCMCpack, ramcmc, rjags, etc.\\nSoftware for Flexible Bayesian Modeling and Markov Chain Sampling, by Radford Neal.\\nStan\\n\\n\\n== External links ==\\nMCMC sampling and other methods in a basic overview, by Alexander Mantzaris (original link - now broken)\\nInteracting Metropolis-Hastings methodologies\\nMCL - a cluster algorithm for graphs, by Stijn van Dongen\\nPyMC - Python module implementing Bayesian statistical models and fitting algorithms, including Markov chain Monte Carlo.\\nIA2RMS is a Matlab code of the Independent Doubly Adaptive Rejection Metropolis Sampling method for drawing from the full-conditional densities within a Gibbs sampler.\\n\\n\\n== References ==',\n",
       "       'Pubget Corp is a wholly owned subsidiary of Copyright Clearance Center that develops cloud-based search and content access tools for scientists. It provides advertising services, enterprise search services, and a public search engine. The company was founded in 2007 by Beth Israel Hospital clinical pathologist, Ramy Arnaout, out of his own need to find papers. Pubget moved its headquarters from Cambridge, Massachusetts to Boston’s Innovation District in 2011.\\nPubget.com is a free service for non-profit institutions and their libraries and researchers. The site provides direct access to full-text content from 450 libraries around the world. It was announced in January 2012 that Pubget was acquired by Copyright Clearance Center.\\n\\n\\n== Products and Services ==\\nSearch Engine\\nPubget’s search engine retrieves article citations and full text PDFs from PubMed, ArXiv, Karger, American Society for Microbiology, IEEE, RSS feeds, XML from publishers, and Open Archive sources. The company’s search engine contains over 28 million scientific documents and adds 10,000 papers each day. Pubget creates a link directly from the article citation to the paper itself via a continuously updated database of links. Because of this database, users are directly linked from a citation to the full-text paper.\\nAccess to closed full-text PDFs is granted through the institution’s subscriptions. Pubget does not bypass copyright laws and will display only the abstract of restricted papers if the end user does not have institutional access.\\nPaperStats\\nPubget PaperStats is a usage and spend analysis tool for libraries. PaperStats automatically harvests serials usage statistics delivering consolidated usage, cost, and other reports directly from publishers. Content performance can be assessed through cost-per-view analysis. Upon introduction, PaperStats was beta tested with the USC Norris Medical Library and yielded positive results for Pubget, USC and the library community.\\nPaperStore\\nThe Pubget PaperStore provides Pubget.com users the option of purchasing full text papers from thousands of journals on the search engine results page. Content rights and delivery is provided by document delivery vendor, Reprints Desk.\\nAdvertising\\nPubget provides several advertising solutions. Customers include Bio-Rad, Agilent, and other scientific brands. Ads are matched with paper content via contextual targeting. For example, manufacturers of a piece of scientific equipment will pay to advertise alongside a paper that mentions using said product. Pubget, however, does not reveal data on individual users and their searches.\\nTextmining\\nPubget’s textmining technology allows research and development teams to uncover specific text strings across large groups of papers.\\nPaperStream\\nPaperStream is a web app that allows lab teams to share, store, and find documents all in one place. PaperStream organizes companies’ subscriptions, purchased papers, and internal documents into an automated library database.\\nAPI\\nPubget’s API provides access to its search and linking technology from third-party websites.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website\\nGot PubMed? Pubget Searches and Delivers Scientific PDFs\\nUCSF Pubget page\\nPubMed Portuguese\\nPubget Speeds Up Science Journal Searches, Provides Marketing Tools\\nPubget RSS and Firefox Download Extension\\nReprints Desk',\n",
       "       'A face recognition system is a computer application capable of identifying or verifying a person from a digital image or a video frame from a video source. One of the ways to do this is by comparing selected facial features from the image and a face database.\\nIt is typically used in security systems and can be compared to other biometrics such as fingerprint or eye iris recognition systems. Recently, it has also become popular as a commercial identification and marketing tool.\\n\\n\\n== Techniques for face acquisition ==\\n\\n\\n=== Traditional ===\\nSome face recognition algorithms identify facial features by extracting landmarks, or features, from an image of the subject\\'s face. For example, an algorithm may analyze the relative position, size, and/or shape of the eyes, nose, cheekbones, and jaw. These features are then used to search for other images with matching features. Other algorithms normalize a gallery of face images and then compress the face data, only saving the data in the image that is useful for face recognition. A probe image is then compared with the face data. One of the earliest successful systems is based on template matching techniques applied to a set of salient facial features, providing a sort of compressed face representation.\\nRecognition algorithms can be divided into two main approaches, geometric, which looks at distinguishing features, or photometric, which is a statistical approach that distills an image into values and compares the values with templates to eliminate variances.\\nPopular recognition algorithms include principal component analysis using eigenfaces, linear discriminant analysis, elastic bunch graph matching using the Fisherface algorithm, the hidden Markov model, the multilinear subspace learning using tensor representation, and the neuronal motivated dynamic link matching.\\n\\n\\n=== 3-dimensional recognition ===\\nA newly emerging trend, claimed to achieve improved accuracy, is three-dimensional face recognition. This technique uses 3D sensors to capture information about the shape of a face. This information is then used to identify distinctive features on the surface of a face, such as the contour of the eye sockets, nose, and chin.\\nOne advantage of 3D face recognition is that it is not affected by changes in lighting like other techniques. It can also identify a face from a range of viewing angles, including a profile view. Three-dimensional data points from a face vastly improve the precision of face recognition. 3D research is enhanced by the development of sophisticated sensors that do a better job of capturing 3D face imagery. The sensors work by projecting structured light onto the face. Up to a dozen or more of these image sensors can be placed on the same CMOS chip—each sensor captures a different part of the spectrum....\\nEven a perfect 3D matching technique could be sensitive to expressions. For that goal a group at the Technion applied tools from metric geometry to treat expressions as isometries A company called Vision Access created a firm solution for 3D face recognition. The company was later acquired by the biometric access company Bioscrypt Inc. which developed a version known as 3D FastPass.\\nA new method is to introduce a way to capture a 3D picture by using three tracking cameras that point at different angles; one camera will be pointing at the front of the subject, second one to the side, and third one at an angle. All these cameras will work together so it can track a subject’s face in real time and be able to face detect and recognize.\\n\\n\\n=== Skin texture analysis ===\\nAnother emerging trend uses the visual details of the skin, as captured in standard digital or scanned images. This technique, called skin texture analysis, turns the unique lines, patterns, and spots apparent in a person’s skin into a mathematical space.\\nTests have shown that with the addition of skin texture analysis, performance in recognizing faces can increase 20 to 25 percent.\\n\\n\\n=== Thermal cameras ===\\nA different form of taking input data for face recognition is by using thermal cameras, by this procedure the cameras will only detect the shape of the head and it will ignore the subject accessories such as glasses, hats, or make up. A problem with using thermal pictures for face recognition is that the databases for face recognition is limited. Diego Socolinsky, and Andrea Selinger (2004) research the use of thermal face recognition in real life, and operation sceneries, and at the same time build a new database of thermal face images. The research uses low-sensitive, low-resolution ferro-electric electrics sensors that are capable of acquire long wave thermal infrared (LWIR). The results show that a fusion of LWIR and regular visual cameras has the greater results in outdoor probes. Indoor results show that visual has a 97.05% accuracy, while LWIR has 93.93%, and the Fusion has 98.40%, however on the outdoor proves visual has 67.06%, LWIR 83.03%, and fusion has 89.02%. The study used 240 subjects over the period of 10 weeks to create the new database. The data was collected on sunny, rainy, and cloudy days.\\n\\n\\n== Notable users and deployments ==\\nThe Australian people and New Zealand Customs Services have an automated border processing system called SmartGate that uses face recognition. The system compares the face of the individual with the image in the e-passport microchip to verify that the holder of the passport is the rightful owner.\\nLaw enforcement agencies in the United States, including the Los Angeles County Sheriff, use arrest mugshot databases in their forensic investigative work. Law enforcement has been rapidly building a database of photos in recent years.\\nThe U.S. Department of State operates one of the largest face recognition systems in the world with 117 million American adults including mostly law abiding citizens in its database. The photos are typically drawn from driver\\'s license photos. Although it is still far from completion, it is being put to use in certain cities to give clues as to who was in the photo. The FBI uses the photos as an investigative lead not for positive identification.\\nIn recent years Maryland has used face recognition by comparing people\\'s faces to their driver\\'s license photos. The system drew controversy when it was used in Baltimore to arrest unruly protesters after the death of Freddie Gray in police custody. Many other states are using or developing a similar system however some states have laws prohibiting its use.\\nThe FBI has also instituted its Next Generation Identification program to include face recognition, as well as more traditional biometrics like fingerprints and iris scans, which can pull from both criminal and civil databases.\\nThe Tocumen International Airport in Panama operates an airport-wide surveillance system using hundreds of live face recognition cameras to identify wanted individuals passing through the airport.\\nMajor Canadian airports will be using a new facial recognition program as part of the Primary Inspection Kiosk program that will compare people\\'s faces to their passports. This program will first come to Ottawa International Airport in early 2017 and to other airports in 2018.\\nIn 2017, Time & Attendance company ClockedIn released facial recognition as a form of attendance tracking for businesses and organisations looking to have a more automated system of keeping track of hours worked as well as for security and health & safety control.\\nIn May 2017, A man was arrested using an Automatic Facial Recognition (AFR) system mounted on a van operated by the South Wales Police. Ars Technica reported that \"this appears to be the first time it[AFR] has led to an arrest\".\\n\\n\\n=== Additional uses ===\\nIn addition to being used for security systems, authorities have found a number of other applications for face recognition systems. While earlier post-9/11 deployments were well publicized trials, more recent deployments are rarely written about due to their covert nature.\\nAt Super Bowl XXXV in January 2001, police in Tampa Bay, Florida used Viisage face recognition software to search for potential criminals and terrorists in attendance at the event. 19 people with minor criminal records were potentially identified.\\nIn the 2000 presidential election, the Mexican government employed face recognition software to prevent voter fraud. Some individuals had been registering to vote under several different names, in an attempt to place multiple votes. By comparing new face images to those already in the voter database, authorities were able to reduce duplicate registrations. Similar technologies are being used in the United States to prevent people from obtaining fake identification cards and driver’s licenses.\\nThere are also a number of potential uses for face recognition that are currently being developed. For example, the technology could be used as a security measure at ATMs. Instead of using a bank card or personal identification number, the ATM would capture an image of the customer\\'s face, and compare it to the account holder\\'s photo in the bank database to confirm the customer\\'s identity.\\nFace recognition systems are used to unlock software on mobile devices. An independently developed Android Marketplace app called Visidon Applock makes use of the phone\\'s built-in camera to take a picture of the user. Face recognition is used to ensure only this person can use certain apps which they choose to secure.\\nFace detection and face recognition are integrated into the iPhoto application for Macintosh, to help users organize and caption their collections.\\nBecause of certain limitations of fingerprint recognition systems, face recognition systems could be used as an alternative way to confirm employee attendance at work for the claimed hours.\\nAnother use could be a portable device to assist people with prosopagnosia in recognizing their acquaintances.\\nIn September 2017, Apple Inc. launched its new flagship device, iPhone X, with facial recognition technology, named Face ID.\\n\\n\\n== Advantages and disadvantages ==\\n\\n\\n=== Compared to other technologies ===\\nAmong the different biometric techniques, face recognition may not be most reliable and efficient. However, one key advantage is that it does not require the cooperation of the test subject to work. Properly designed systems installed in airports, multiplexes, and other public places can identify individuals among the crowd, without passers-by even being aware of the system. Other biometrics like fingerprints, iris scans, and speech recognition cannot perform this kind of mass identification. However, questions have been raised on the effectiveness of face recognition software in cases of railway and airport security.\\n\\n\\n=== Weaknesses ===\\nFace recognition is far from perfect and struggles to perform under certain conditions. Ralph Gross, a researcher at the Carnegie Mellon Robotics Institute, describes one obstacle related to the viewing angle of the face: \"Face recognition has been getting pretty good at full frontal faces and 20 degrees off, but as soon as you go towards profile, there\\'ve been problems.\"\\nCurrent face recognition still often misidentifies people which can sometimes lead to controversy. Google was criticized for racism in its system when a black couple were misidentified as gorillas. Face recognition software generally doesn\\'t do as well in identifying minorities when most of the subjects used in testing the technology were from the majority group.\\nOther conditions where face recognition does not work well include poor lighting, sunglasses, hats, scarves, beards, long hair, makeup or other objects partially covering the subject’s face, and low resolution images.\\nAnother serious disadvantage is that many systems are less effective if facial expressions vary. Even a big smile can render the system less effective. For instance: Canada now allows only neutral facial expressions in passport photos.\\nThere is also inconstancy in the datasets used by researchers. Researchers may use anywhere from several subjects to scores of subjects, and a few hundred images to thousands of images. It is important for researchers to make available the datasets they used to each other, or have at least a standard dataset.\\n\\n\\n=== Effectiveness ===\\nCritics of the technology complain that the London Borough of Newham scheme has, as of 2004, never recognized a single criminal, despite several criminals in the system\\'s database living in the Borough and the system having been running for several years. \"Not once, as far as the police know, has Newham\\'s automatic face recognition system spotted a live target.\" This information seems to conflict with claims that the system was credited with a 34% reduction in crime (hence why it was rolled out to Birmingham also). However it can be explained by the notion that when the public is regularly told that they are under constant video surveillance with advanced face recognition technology, this fear alone can reduce the crime rate, whether the face recognition system technically works or does not. This has been the basis for several other face recognition based security systems, where the technology itself does not work particularly well but the user\\'s perception of the technology does.\\nAn experiment in 2002 by the local police department in Tampa, Florida, had similarly disappointing results.\\nA system at Boston\\'s Logan Airport was shut down in 2003 after failing to make any matches during a two-year test period.\\nAs of 2016, facial recognition is still not effective for most applications even though the accuracy has been substantially improved. Although systems are often advertised as having accuracy near 100%, this is misleading as the studies often uses much smaller sample sizes than would be necessary for large scale applications. Because facial recognition is not completely accurate, it creates a list of potential matches. A human operator must then look through these potential matches and studies show the operators pick the correct match out of the list only about half the time. This causes the issue of targeting the wrong suspect.\\n\\n\\n=== Privacy issues ===\\nCivil rights right organizations and privacy campaigners such as the Electronic Frontier Foundation and the ACLU express concern that privacy is being compromised by the use of surveillance technologies. Some fear that it could lead to a “total surveillance society,” with the government and other authorities having the ability to know the whereabouts and activities of all citizens around the clock. This knowledge has been, is being, and could continue to be deployed to prevent the lawful exercise of rights of citizens to criticize those in office, specific government policies or corporate practices. Many centralized power structures with such surveillance capabilities have abused their privileged access to maintain control of the political and economic apparatus, and to curtail populist reforms.\\nFace recognition can be used not just to identify an individual, but also to unearth other personal data associated with an individual – such as other photos featuring the individual, blog posts, social networking profiles, Internet behavior, travel patterns, etc. – all through facial features alone. Moreover, individuals have limited ability to avoid or thwart face recognition tracking unless they hide their faces. This fundamentally changes the dynamic of day-to-day privacy by enabling any marketer, government agency, or random stranger to secretly collect the identities and associated personal information of any individual captured by the face recognition system.\\nSocial media web sites such as Facebook have very large numbers of photographs of people, annotated with names. This represents a database which may be abused by governments for face recognition purposes. Face recognition was used in Russia to harass women allegedly involved in online pornography. In Russia there is an app \\'FindFace\\' which can identify faces with about 70% accuracy using the social media app called VK. This app would not be possible in other countries which do not use VK as their social media platform photos are not stored the same way as with VK.\\nIn July 2012, a hearing was held before the Subcommittee on Privacy, Technology and the Law of the Committee on the Judiciary, United States Senate, to address issues surrounding what face recognition technology means for privacy and civil liberties.\\nIn 2014, the National Telecommunications and Information Association (NTIA) began a multi-stakeholder process to engage privacy advocates and industry representatives to establish guidelines regarding the use of face recognition technology by private companies. In June 2015, privacy advocates left the bargaining table over what they felt was an impasse based on the industry representatives being unwilling to agree to consent requirements for the collection of face recognition data. The NTIA and industry representatives continued without the privacy representatives, and draft rules are expected to be presented in the spring of 2016.\\nStates have begun enacted legislation to protect citizen\\'s biometric data privacy. Illinois enacted the Biometric Information Privacy Act in 2008. Facebook\\'s DeepFace has become the subject of several class action lawsuits under the Biometric Information Privacy Act, with claims alleging that Facebook is collecting and storing face recognition data of its users without obtaining informed consent, in direct violation of the Biometric Information Privacy Act. The most recent case was dismissed in January 2016 because the court lacked jurisdiction. Therefore, it is still unclear if the Biometric Information Privacy Act will be effective in protecting biometric data privacy rights.\\n\\n\\n== History ==\\nPioneers of automated face recognition include Woody Bledsoe, Helen Chan Wolf, and Charles Bisson.\\nDuring 1964 and 1965, Bledsoe, along with Helen Chan and Charles Bisson, worked on using the computer to recognize human faces (Bledsoe 1966a, 1966b; Bledsoe and Chan 1965). He was proud of this work, but because the funding was provided by an unnamed intelligence agency that did not allow much publicity, little of the work was published. Given a large database of images (in effect, a book of mug shots) and a photograph, the problem was to select from the database a small set of records such that one of the image records matched the photograph. The success of the method could be measured in terms of the ratio of the answer list to the number of records in the database. Bledsoe (1966a) described the following difficulties:\\nThis project was labeled man-machine because the human extracted the coordinates of a set of features from the photographs, which were then used by the computer for recognition. Using a graphics tablet (GRAFACON or RAND TABLET), the operator would extract the coordinates of features such as the center of pupils, the inside corner of eyes, the outside corner of eyes, point of widows peak, and so on. From these coordinates, a list of 20 distances, such as width of mouth and width of eyes, pupil to pupil, were computed. These operators could process about 40 pictures an hour. When building the database, the name of the person in the photograph was associated with the list of computed distances and stored in the computer. In the recognition phase, the set of distances was compared with the corresponding distance for each photograph, yielding a distance between the photograph and the database record. The closest records are returned.\\nBecause it is unlikely that any two pictures would match in head rotation, lean, tilt, and scale (distance from the camera), each set of distances is normalized to represent the face in a frontal orientation. To accomplish this normalization, the program first tries to determine the tilt, the lean, and the rotation. Then, using these angles, the computer undoes the effect of these transformations on the computed distances. To compute these angles, the computer must know the three-dimensional geometry of the head. Because the actual heads were unavailable, Bledsoe (1964) used a standard head derived from measurements on seven heads.\\nAfter Bledsoe left PRI in 1966, this work was continued at the Stanford Research Institute, primarily by Peter Hart. In experiments performed on a database of over 2000 photographs, the computer consistently outperformed humans when presented with the same recognition tasks (Bledsoe 1968). Peter Hart (1996) enthusiastically recalled the project with the exclamation, \"It really worked!\"\\nBy about 1997, the system developed by Christoph von der Malsburg and graduate students of the University of Bochum in Germany and the University of Southern California in the United States outperformed most systems with those of Massachusetts Institute of Technology and the University of Maryland rated next. The Bochum system was developed through funding by the United States Army Research Laboratory. The software was sold as ZN-Face and used by customers such as Deutsche Bank and operators of airports and other busy locations. The software was \"robust enough to make identifications from less-than-perfect face views. It can also often see through such impediments to identification as mustaches, beards, changed hair styles and glasses—even sunglasses\".\\nIn about January 2007, image searches were \"based on the text surrounding a photo,\" for example, if text nearby mentions the image content. Polar Rose technology can guess from a photograph, in about 1.5 seconds, what any individual may look like in three dimensions, and claimed they \"will ask users to input the names of people they recognize in photos online\" to help build a database. Identix, a company out of Minnesota, has developed the software, FaceIt. FaceIt can pick out someone’s face in a crowd and compare it to databases worldwide to recognize and put a name to a face. The software is written to detect multiple features on the human face. It can detect the distance between the eyes, width of the nose, shape of cheekbones, length of jawlines and many more facial features. The software does this by putting the image of the face on a faceprint, a numerical code that represents the human face. Face recognition software used to have to rely on a 2D image with the person almost directly facing the camera. Now, with FaceIt, a 3D image can be compared to a 2D image by choosing 3 specific points off of the 3D image and converting it into a 2D image using a special algorithm that can be scanned through almost all databases. \\u2003 In 2006, the performance of the latest face recognition algorithms were evaluated in the Face Recognition Grand Challenge (FRGC). High-resolution face images, 3-D face scans, and iris images were used in the tests. The results indicated that the new algorithms are 10 times more accurate than the face recognition algorithms of 2002 and 100 times more accurate than those of 1995. Some of the algorithms were able to outperform human participants in recognizing faces and could uniquely identify identical twins. \\nU.S. Government-sponsored evaluations and challenge problems have helped spur over two orders-of-magnitude in face-recognition system performance. Since 1993, the error rate of automatic face-recognition systems has decreased by a factor of 272. The reduction applies to systems that match people with face images captured in studio or mugshot environments. In Moore\\'s law terms, the error rate decreased by one-half every two years.\\nLow-resolution images of faces can be enhanced using face hallucination. Further improvements in high resolution, megapixel cameras in the last few years have helped to resolve the issue of insufficient resolution.\\n\\n\\n== Emotion detection ==\\nFacial recognition systems have been used for emotion recognition In 2016 Facebook acquired emotion detection startup FacioMetrics.\\n\\n\\n== Anti facial recognition systems ==\\nIn January 2013 Japanese researchers from the National Institute of Informatics created \\'privacy visor\\' glasses that uses nearly infrared light to make the face underneath it unrecognizable to face recognition software. The latest version uses a titanium frame, light-reflective material and a mask which uses angles and patterns to disrupt facial recognition technology through both absorbing and bouncing back light sources. In December 2016 a form of anti-CCTV and facial recognition sunglasses called \\'reflectacles\\' were invented by a custom-spectacle-craftsmen based in Chicago named Scott Urban. They reflect infrared and, optionally, visible light which makes the users face a white blur to cameras. The project easily surpassed its crowdfunding goal of $28,000 and reflectacles will be commercially available by June 2017. It is conceivable that such technology might be fused with future head-mounted displays such as potential successors of HoloLens.\\nAnother method to protect from facial recognition systems are specific haircuts and make-up patterns that prevent the used algorithms to detect a face.\\n\\n\\n== See also ==\\n\\nLists\\nList of computer vision topics\\nList of emerging technologies\\nOutline of artificial intelligence\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nWhat are Biometrics? White Paper Published by Aware, Inc., January 2014\\nFarokhi, Sajad; Shamsuddin, Siti Mariyam; Flusser, Jan; Sheikh, U.U; Khansari, Mohammad; Jafari-Khouzani, Kourosh (2014). \"Near infrared face recognition by combining Zernike moments and undecimated discrete wavelet transform\". Digital Signal Processing. 31 (1). doi:10.1016/j.dsp.2014.04.008. \\n\"The Face Detection Algorithm Set to Revolutionize Image Search\" (Feb. 2015), MIT Technology Review\\nGarvie, Clare; Bedoya, Alvaro; Frankle, Jonathan (October 18, 2016). Perpetual Line Up: Unregulated Police Face Recognition in America. Center on Privacy & Technology at Georgetown Law. Retrieved October 22, 2016. \\n\"Facial Recognition Software \\'Sounds Like Science Fiction,\\' but May Affect Half of Americans\". As It Happens. Canadian Broadcasting Corporation. October 20, 2016. Retrieved October 22, 2016.  Interview with Alvaro Bedoya, executive director of the Center on Privacy & Technology at Georgetown Law and co-author of Perpetual Line Up: Unregulated Police Face Recognition in America.\\n\\n\\n== External links ==\\n Media related to Face recognition system at Wikimedia Commons\\n\\nA Photometric Stereo Approach to Face Recognition\". University of the West of England. http://www1.uwe.ac.uk/et/mvl/projects/facerecognition.aspx',\n",
       "       \"OpenXava is a web framework for developing business applications in an effective way. It not only allows rapid and easy development of CRUD modules and report generation, but also provides flexibility to develop complex real life business applications like accounting packages, customer relationship, invoicing, warehouse management, etc.\\nOpenXava allows developers to define applications with POJOs, JPA and Java 5 annotations.\\nCurrently OpenXava generates Java web applications (Java EE) which can be deployed in any Java Portal Server (JSR168) as portlet applications.\\nThe essence of OpenXava is that the developer defines instead of programming, and the framework automatically provides the user interface, the data access, the default behavior, etc. In this way, all common issues are solved easily, but the developer always has the possibility of manually programming any part of the application, in this way it is flexible enough to solve any particular cases. OpenXava is based on the concept of the business component.\\n\\n\\n== Business component versus MVC ==\\nA business component includes all software artifacts needed to define a business concept. OpenXava is a business component framework because it allows defining all information about a business concept in a single place. For example, for defining the concept of Invoice, in OpenXava a single file (Invoice.java) is used, and all information about invoice concept (including data structure, user interface layout, mapping with database, validations, calculations, etc.) is defined there.\\nIn an MVC framework the business logic (the Model), the user interface (the View) and the behavior (the Controller) are defined separately. These types of frameworks are useful if the rate of change of logic and data structures is low and the possibility of changing user interface technology or data access technology is high.\\nIn OpenXava, the addition of a new field to an Invoice only requires changing a single file: Invoice.java. But MVC frameworks are cumbersome when changes to structure and data are very frequent (as in the business application case). Imagine the simplest change, adding a new field to an Invoice. In the MVC framework the developer must change three sections: the user interface, the model class and the database table. Moreover, if the developer uses Java EE design patterns he has to change the DTO class, the Facade Session Bean, the Entity Bean mapping, etc.\\nUsing OpenXava makes it possible to allocate the development work using a business logic oriented task distribution. For example, Invoice to one developer, Delivery to another, as opposed to technology layer business logic to one developer, user interface to another.\\n\\n\\n== Features ==\\nThese are some of the main features of OpenXava:\\nHigh productivity for developing business applications.\\nShort learning curve and easy to use.\\nFlexible enough to create sophisticated applications.\\nIt is possible to insert custom functionality in any place.\\nBased on the concept of business component.\\nGenerate a full Java EE application, including AJAX user interface.\\nSupports any application server (Tomcat, JBoss, WebSphere, etc.).\\nSupports JSR168: All OpenXava modules are standard portlets too.\\nEJB3 JPA complete support\\nIt is tested with the portals: Jetspeed-2, WebSphere Portal, Liferay, eXo Platform and Stringbeans.\\nEasy integration of reports made with JasperReports (that use Jakarta Velocity and VTL - Velocity Template Language)\\nLicensed under GNU Lesser General Public License.\\nAll labels and messages are in English, Spanish, German, Polish, Indonesian, French, Chinese, Italian and Catalan, with more coming.\\n\\n\\n== See also ==\\nComparison of web frameworks\\nJava EE\\nModel driven development\\nWakanda (inspired OpenXava)\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website\\n'Business component' definition by Peter Herzum\",\n",
       "       'Lorenzo patient record systems are a type of Electronic health record provided by CSC, originally as part of the United Kingdom government’s National Programme for IT (NHS Connecting for Health) in the NHS.\\nThere is a long history of negotiations between the NHS and the company.\\nOn 4 September 2012, the UK Department of Health announced that whilst it was \"dismantling\" the National Programme for IT, Lorenzo would be supplied under a new legally binding agreement with CSC.\\nUniversity Hospitals of Morecambe Bay NHS Foundation Trust was the first to deploy the technology. It implemented electronic patient record system Lorenzo Release 1.9 in June 2010.\\nHumber NHS Foundation Trust was the first mental health organisation to use the CSC Lorenzo patient record systems in June 2012.\\nLorenzo systems are being introduced to Warrington & Halton Hospitals NHS Foundation Trust during 2015.\\nIn June 2015, a Digital Health Intelligence article stated that Hull and East Yorkshire Hospitals NHS Trust and Norfolk and Suffolk NHS Foundation Trust had gone live with Lorenzo. In July 2015, Digital Health Intelligence reported CSC as stating that 19 NHS Trusts had contracted to take the Lorenzo system.\\nGeorge Eliot Hospital NHS Trust, Ipswich Hospital NHS Trust, Tameside Hospital NHS Foundation Trust and Hull and East Yorkshire Hospitals NHS Trust are also implementing Lorenzo under a financial support package which has been described as controversial.\\nIn June 2013 senior executives from the NHS were called before the parliamentary Public Accounts Committee, where chair Margaret Hodge called CSC a “rotten company” and said the Lorenzo system was “hopeless”.\\nDeployments of Lorenzo have not been without reported teething troubles. Delays in the provision of data to NHS England\\'s waiting list system were linked to Lorenzo implementations in an HSJ article in May 2014. Tameside Hospital NHS Foundation Trust’s April risk register awarded its Lorenzo project the highest possible risk rating – 25 – citing “potential risks to patient safety quality, information governance and performance trajectories”. Walsall Healthcare NHS Trust\\'s May 2014 board meeting noted it had been forced to “recruit 25 additional staff” to address “a number of issues [which] have arisen as Lorenzo moves to business as usual”, including “backlogs, clinic restructuring and un-outcomed outpatient clinic forms”. Hull and East Yorkshire Hospitals NHS Trust’s May 2014 risk register said plans to deploy Lorenzo might be “unrealistic”, and that it had “insufficient capacity and insufficient funding” to support the project.\\nNorth Bristol NHS Trust went live with Lorenzo in November 2015, replacing a Cerner system. North Bristol was the first NHS trust in the South of England to take the system as part of an open procurement exercise outside of CSC\\'s central relationship with the NHS. \\n\\n\\n== References ==',\n",
       "       'Order to cash (O2C or OTC) normally refers to one of the top-level (context level) business process for receiving and processing customer orders. Other top-level business processes include \"Opportunity to Order\", \"Procure to Pay\" (P2P), \"Issue to Complete\" (for manufacturing production) \"Hire to Retire\", \"Concept to Launch\" (for innovation and new product development) and \"Sustain and Retain\" (for customer service and support)\\nThe context level processes are utilized in a number of ways by businesses such as business process reengineering, aligning enterprise architectures and IT solutions as well as \"blueprinting\" as part of Enterprise Resource Planning (ERP) system implementations such as SAP, Oracle, Microsoft Dynamics and NetSuite.\\nIn many business models, a contractual relationship is established first via a Contract or Subscription. Orders are then received via different sales channels, such as phone, fax, email, internet or sales person. The contractual relationship is confirmed and the Orders are fulfilled through shipping and logistics. On completion of key events an invoice is generated and booked as Sales (subject to \"Revenue Recognition\" requirements). If payment has not already been received, the debt is recorded and pursued through dunning cycles until the funds are received. Order to Cash is completed by the Customer Care process (inquiries, requests and complaints).\\nIf we consider the ERP system flow, this is typically categorized into the following nine sub-processes:\\nCustomer presence\\nOrder entry (creation of order / booking of order)\\nOrder fulfillment (physical and digital fulfillment)\\nDistribution\\nInvoicing\\nCustomer payments / collection\\nCash application\\nDeductions (If invoice short paid by customer)\\nCollection',\n",
       "       \"IMS MAXIMS is a supplier of electronic health record software to the public and private sectors in UK and the Republic of Ireland.\\nAs of December 2016, its products were in use across 180 healthcare organisations, by 30,000 users each day for 13 million patients.\\nIt has offices in Milton Keynes, Dublin and Romania.\\nIn 2015 the company released an open source version of its software – openMAXIMS - which acute trusts can use without a licence fee and alter the code to tailor the system to their needs. Its open technology has increased collaboration in the development of the software which has resulted in better clinical engagement. The company is seen as a pioneer in the use of open-source software in the NHS.\\nThe company has established a community interest company (CIC) to support the development of the open-source software it has developed. Customers Taunton and Somerset NHS Foundation Trust, Blackpool Teaching Hospitals NHS Foundation Trust, St Helens and Knowsley Teaching Hospitals NHS Trust, and private healthcare group, Ramsay Healthcare UK are members of the CIC.\\nIn 2016, Taunton and Somerset NHS Foundation Trust, the first hospital in the UK to deploy openMAXIMS electronic health record, was named by Health Secretary Jeremy Hunt as a Global Digital Exemplar. The software will save the trust £600,000 a year by 2018.\\nThe company is a founding member of INTEROPen, an organisation that aims to accelerate, promote, and encourage the use of open source solutions within health & social care; and is part of Code4Health, an initiative supporting the best practice of digital technology in the NHS.\\nIMS MAXIMS services are available to purchase on the UK Government's Crown Commercial Service G Cloud 8 Framework, NHS Shared Business Services Framework and Digital Outcomes and Specialists Framework.\\nThe company has been shortlisted for two awards - Health Investor IT Innovator of the Year 2016 and Biomnis Healthcare Innovation 2013 - and was highly commended for eHealth Insider's Healthcare IT Product Innovation Award 2015.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nCompany website\",\n",
       "       'Strands, founded in 2004 in Oregon (USA) and Barcelona (Spain), is a FinTech software company, developing solutions for banks and merchants to enable them to generate higher customer engagement and create new revenue through digital marketing channels. Strands is recognized by the financial industry as “The Fintech Partner for Banks”, having collaborated on more than 600 bank implementations with one hundred million customers worldwide. Strands Finance Suite is a set of white-label solutions including Personal Financial Management (PFM), Business Financial Management (BFM), and Customer-Linked Offers (CLO).\\nStrands began life by developing personalization and recommendation solutions for the music industry. Apple Inc. acquired these early solutions together with a portfolio of 32 patents, allowing the company to focus its innovation efforts on the research and development of financial technologies. Strands Finance Suite today includes a portfolio of products that share a common foundation based on Big Data Processing, Artificial Intelligence, Machine Learning, Open API, and best-in-class Customer Experience.\\nStrands is a founding member of SME Finance Forum, managed by the International Finance Corporation - member of the World Bank Group, and is advisory member of MobeyForum, leading Open Banking working group. In 2007, Strands organized a summer school on Recommender Systems, which led to the creation of the ACM Conference on Recommender Systems.\\n\\n\\n== Products ==\\nPersonal Financial Management (PFM), an award-winning white label digital money management solution. In 2008 Strands deployed the first PFM in Europe with BBVA and launched B2C application MoneyStrands in the USA. Since then Strands PFM has been implemented by the world’s largest banks including Barclays, Deutsche Bank, Commercial Bank of Africa, Huntington National Bank and Bank of Montreal.\\nBusiness Financial Management (BFM), a comprehensive digital banking solution for managing business financials, designed especially for SMEs.\\nCustomer-Linked Offers (CLO), a smart marketing platform that enables merchants to increase sales and acquire new customers by sending contextual offers through digital banking channels. This solution has been implemented by PostFinance, the fifth-largest retail financial institution in Switzerland\\nAPI Hub: a “one-stop-shop” solution that enables banks to aggregate external accounts and provide customers with a holistic picture of their finances. It is done by accessing heterogeneous financial information from different banks and displaying it in a convenient, easy-to-understand format.\\nRecommender (REC): recommendation software solution enabling banks’ marketing teams to plan, execute and analyze smart campaigns for both financial and third-party products and services.\\nMoneyStrands, the B2C application of Strands PFM, currently available in the USA.\\n\\n\\n== Clients ==\\nFrom its Barcelona HQ and offices in Miami, Buenos Aires, Mexico and Kuala Lumpur, Strands serves financial institutions including Barclays, Deutsche Bank, BBVA, BNP Paribas, Huntington National Bank, Commercial Bank of Africa (CBA), Bank of Montreal (BMO), and PostFinance among others.\\nOne of the latest implementations of Strands PFM was with Commercial Bank of Africa (CBA). Kenya’s largest privately owned bank, launched the region’s first Digital Banking Service, CBA Loop targeting millennials and tech-savvy customers. This marked the first end-to-end full digital banking proposition in Eastern Africa and has sparked the attention of The Economist, African Banker and the IFC SME Finance Forum.\\n\\n\\n== References ==',\n",
       "       'Oracle Enterprise Service Bus (Oracle ESB), a fundamental component of Oracle\\'s Services-Oriented Architecture suite of products, provides seamless integration of data and enterprise applications within an organisation and their connected ( \"extended\" or “virtual”) enterprises.\\n\\n\\n== Details ==\\nThis release of Oracle Retail Integration Bus (RIB) Essentials includes changes in architecture, technology stack, and deployment Oracle ESB is technically an \\'enterprise service bus\\' designed and implemented in an Oracle Fusion Architecture\\'s SOA environment; to simplify the interaction and communication between existing Oracle products, third-party applications, or any combination of these.\\nAs a software architecture model for distributed computing it is a specialty variant of the more general client server software architecture model and promotes strictly asynchronous message oriented design for communication and interaction between applications. Its primary use is in Enterprise Application Integration of heterogeneous and complex landscapes of an organisation, and thus enabling its easy management.\\nAn ESB service is designed and configured with Oracle JDeveloper and Oracle ESB Control user interfaces. It is then registered to an ESB Server. The ESB Server supports multiple protocol bindings for message delivery, including HTTP/SOAP, JMS, JCA, WSIF and Java, using synchronous/asynchronous, request/reply or publish/subscribe models. Currently, the ESB Server does not support Remote Method Invocation.\\nOracle Retail Integration Bus (RIB) Essentials should not be confused with Oracle Service Bus (OSB). ESB was developed by Oracle. OSB, formerly known as Aqualogic Service Bus, was acquired when Oracle bought BEA Systems. The two products are related and interchangeable.\\n\\n\\n== Components ==\\nOracle Enterprise Service Bus contains the following components:\\nESB Server\\nOracle ESB Control\\nESB Metadata Server\\nOracle JDeveloper\\n\\n\\n== Features ==\\nOracle Enterprise Service Bus application-integration features fall into the following categories:\\nServer Capabilities\\nConnectivity\\nSOAP invocations services\\nWSIF\\nAdapter services\\nFile/FTP adapter service\\nDatabase adapter service\\nJMS adapter service\\nMQ adapter service\\nAQ adapter service\\nOracle Applications (OA) adapter services\\nCustom adapter service\\n\\nDocument Transformation : XSLT and MFL\\nContent-Based and Header-Based Routing\\nTight integration with Oracle BPEL Process Manager\\n\\nManagement and Monitoring Capabilities\\nESB Control, the central point for metadata and configuration changes that take effect immediately\\nVisual representation of end-to-end service relationships\\nMinimal overhead end-to-end message instance tracking and monitoring\\nError Hospital - automated and manual means for individual and bulk message replays\\n\\n\\n== See also ==\\nOracle Fusion Middleware\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nProduct page\\nDocumentation\\nhttp://www.oracle.com/technology/products/integration/service-bus/docs/Oracle-Service-Bus-SOD.pdf\\nhttp://orasoa.blogspot.com/2008/11/who-is-best-osb-or-esb.html',\n",
       "       'Grant management software is a program or application that assists fund-seeking organizations such as non-profits and universities in administering and automating the grant process. Functions can include grant discovery, budget planning, peer collaboration, regulatory compliance, proposal submission, administrative reporting and project tracking. Available as self-hosted programs that are installed on the organization\\'s servers, or as web-based cloud applications that are hosted on the provider\\'s servers, grant management software helps grant managers, principal investigators, researchers and other individuals ease grant-related administrative burdens.\\n\\n\\n== Grant management software roles ==\\nA grant manager (or grant administrator) can be responsible for many tasks—from grant writing to regulatory compliance. He or she can also be responsible for identifying grant project teams and ensuring teams are communicating effectively. These tasks are often time consuming. Grant management software is designed to reduce the time spent on these activities by automating functions such as opportunity discovery, peer collaboration and workflow tracking. Additionally grants management software can streamline granting activities relating to confirming the tax-exempt status of a not-for-profit as well as cross checking applicants against various terrorist watch lists such as OFAC.\\nOther roles include applicants (both individuals and organizations), researchers, reviewers and any other party that may need to be involved in the grant making processes.\\nGrant management software comes in multiple variations, and each offers its own set of tools to help streamline the management of the pre- and post-award processes.\\nThe pre-award process encompasses everything done before a grant is awarded, such as searching for specific grant types open for application, writing and submitting the grant application, and receiving the rejection or denial letter from the potential grantor. The post-award process encompasses tasks after an award is won, such as purchasing research equipment, tracking and certifying research efforts, accounting tasks, and reporting to the grantor or grantors.\\nSome software variants provide features for the entire lifecycle of a grant. Other solutions offer comprehensive and targeted services for the pre-award process. Others focus on the grant discovery part of the pre-award process, yet others offer some post-award services.\\nMore comprehensive solutions offer functionality that addresses all of the above aspects.\\nMost grant management solutions are available as a hosted service. Under this model, customers pay vendors for online access to the software. Commonly called SaaS (software as a service) or a cloud service, hosted software is available as an application that is run at vendors’ own facilities. One of the benefits of hosted software is that customers often need little or no internal IT support. Despite some concern over security, hosted services are usually more secure than nonprofits’ own IT systems.\\n\\n\\n== Grant management software market ==\\nMany nonprofits, schools and universities rely on grant funding. Each year, all U.S. grant sources give an estimated $1 trillion in grant money. The federal government alone spent $489 billion in grant funding in fiscal 2006. there is often confusion regarding the term Grant management in that many Grant managers control the disbursement of grant funds while other grant managers control the usage of received grant funds. this is an important distinction when deciding on the correct software for your organisation.\\nGrant management software companies operate in the information-management market.\\n\\n\\n== Grant discovery ==\\nGrant management software can help customers find grants by automatically searching known funding sources and alerting users when applicable grant opportunities are available. One site that grant discovery solutions can search is Grants.gov, which lists opportunities from 26 federal grant-making organizations. Other funding sources that can be included are foundations. There are hundreds of foundations in the United States, the top three being the Bill & Melinda Gates Foundation, Ford Foundation and J. Paul Getty Trust, which have combined assets of $54.1 billion. In addition, some discovery solutions search for grants that are offered at the state level.\\n\\n\\n== Grant collaboration ==\\nPreparing for award submissions, finding funding opportunities, and managing grant projects takes considerable collaboration. Some grant management software offer collaboration solutions to make this process easier. Collaboration solutions can help users review grant opportunities, vote on opportunities to apply for, and communicate with other project peers.\\nA select few software vendors deploy social-media applications to simplify collaboration, which help limit the sometimes cumbersome serial communications process of emails. Increasingly, researchers and others involved in the grant process are adept in modern technologies such as social media. Older professionals are using social media, too; according to a 2010 Pew Research Center poll, 47 percent of adults aged 50 to 64 used sites such as Facebook. As a result, social media tools are increasingly being used for business communications purposes, including the business of managing the grant process.\\n\\n\\n== Grant tracking and reporting ==\\nOrganizations that receive funding often have to track grant-related activity and report results to grantors. These tasks can include creating and maintaining award documentation, preparing budgets, and ensuring fund use is within grantor compliance. Grant management software can offer solutions for these tasks. It can record who participates and manage grant-related documents such as letter templates as well as export data to programs such as Excel for easier reporting.\\nIn addition to reporting for internal purposes, organizations such as the Foundation Center allow grant makers to export their reports in order to provide analysis on grant making activity on both a micro and macro level\\n\\n\\n== Grant management software tools ==\\nGrant management software is designed to facilitate best practice grants management and ensure transparency in managing government funded program. the greatest challenge for these tools at present is to present the detailed and strategic views of the KPI\\'s associated with the objectives of the Grant giving organisation. More and more government agencies are asked \"how do you know you are making a difference\" so the need for KPI reporting is critical.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nGrants.gov\\nPew Research Center for the People & the Press\\nGrants Managers Network\\nIdealware\\nConsumer\\'s Guide to Grants Management Systems published by Idealware, the Technology Affinity Group, and the Grants Management Network\\nThe GrantsXchange'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df['content'].sample(10).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_lower = content_q_df.content.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: ujson>=1.35 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: pip<10.0.0,>=9.0.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: regex<2017.12.1,>=2017.4.1 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: murmurhash<0.27,>=0.26 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: thinc<6.6.0,>=6.5.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already satisfied: cytoolz<0.9,>=0.8 in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.9,>=0.8->thinc<6.6.0,>=6.5.0->spacy)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Downloading en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz\n",
      "\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz (52.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 52.2MB 58.9MB/s ta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==1.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: spacy<2.0.0,>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: thinc<6.6.0,>=6.5.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: ujson>=1.35 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: murmurhash<0.27,>=0.26 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: regex<2017.12.1,>=2017.4.1 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: pip<10.0.0,>=9.0.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: cytoolz<0.9,>=0.8 in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.9,>=0.8->thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "\n",
      "    /opt/conda/lib/python3.6/site-packages/en_core_web_sm/en_core_web_sm-1.2.0\n",
      "    --> /opt/conda/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en').\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from spacy.en import STOP_WORDS\n",
    "from spacy.en import English\n",
    "nlp = English()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text = re.sub('&#39;','',text).lower()\n",
    "    text = re.sub('<br />','',text)\n",
    "    text = re.sub('<.*>.*</.*>','', text)\n",
    "    text = re.sub('\\\\ufeff', '', text)\n",
    "    text = re.sub('[\\d]','',text)\n",
    "    text = re.sub('[^a-z ]','',text)\n",
    "    text = re.sub(\"\\d+\\.\\d*\", \"\", text)\n",
    "    text = ' '.join(i.lemma_ for i in nlp(text) if i.orth_ not in STOP_WORDS)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_q_df['clean_content'] = content_q_df['content'].apply(cleaner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Business software or a business application is...</td>\n",
       "      <td>1037763</td>\n",
       "      <td>Business software</td>\n",
       "      <td>business software business application softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>AccuSystems LLC is an American company headqua...</td>\n",
       "      <td>41270069</td>\n",
       "      <td>AccuSystems</td>\n",
       "      <td>accusystem llc american company headquarter pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Active policy management is business-oriented ...</td>\n",
       "      <td>5211212</td>\n",
       "      <td>Active policy management</td>\n",
       "      <td>active policy management businessorient enterp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Alexandria is browser based cross-platform lib...</td>\n",
       "      <td>28502793</td>\n",
       "      <td>Alexandria (library software)</td>\n",
       "      <td>alexandria browser base crossplatform library ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business_Software</td>\n",
       "      <td>Alteryx is an American computer software compa...</td>\n",
       "      <td>44133735</td>\n",
       "      <td>Alteryx</td>\n",
       "      <td>alteryx american computer software company bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category                                            content  \\\n",
       "0  Business_Software  Business software or a business application is...   \n",
       "1  Business_Software  AccuSystems LLC is an American company headqua...   \n",
       "2  Business_Software  Active policy management is business-oriented ...   \n",
       "3  Business_Software  Alexandria is browser based cross-platform lib...   \n",
       "4  Business_Software  Alteryx is an American computer software compa...   \n",
       "\n",
       "     pageid                          title  \\\n",
       "0   1037763              Business software   \n",
       "1  41270069                    AccuSystems   \n",
       "2   5211212       Active policy management   \n",
       "3  28502793  Alexandria (library software)   \n",
       "4  44133735                        Alteryx   \n",
       "\n",
       "                                       clean_content  \n",
       "0  business software business application softwar...  \n",
       "1  accusystem llc american company headquarter pu...  \n",
       "2  active policy management businessorient enterp...  \n",
       "3  alexandria browser base crossplatform library ...  \n",
       "4  alteryx american computer software company bas...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'parity learning problem machine learn algorithm solve problem guess function give sample x x assurance compute parity bit fix location sample generate distribution input problem easy solve gaussian elimination provide sufficient number sample distribution skew provide algorithm noisy version learn parity noise version sample contain error instead sample x x algorithm provide x y y x small probability noisy version parity learn problem conjecture hard learn error reference avrim blum adam kalai hal wasserman noisetolerant learn parity problem statistical query model j acm adam tauman kalai yishay mansour elad verbin agnostic boosting parity learn proceeding th annual acm symposium theory compute victoria british columbia canada acm httpportalacmorgcitationcfmidod regev lattice learn error random linear code cryptography proceeding thirtyseventh annual acm symposium theory compute baltimore md usa acm httpportalacmorgcitationcfmid',\n",
       "       'structured sparsity regularization class method area research statistical learning theory extend generalize sparsity regularization learning method sparsity structure sparsity regularization method seek exploit assumption output variable y displaystyle y ie response dependent variable learn describe reduce number variable input space x displaystyle x ie domain space feature explanatory variable sparsity regularization method focu select input variable good describe output structure sparsity regularization method generalize extend sparsity regularization method allow optimal selection structure like group network input variable x displaystyle x common motivation use structured sparsity method model interpretability highdimensional learning dimensionality x displaystyle x high number observation n displaystyle n reduction computational complexity structure sparsity method allow incorporate prior assumption structure input variable overlap group nonoverlapp group acyclic graph example us structured sparsity method include face recognition magnetic resonance image mri processing sociolinguistic analysis natural language processing analysis genetic expression breast cancer definition related concept sparsity regularization consider linear kernel regularize empirical risk minimization problem loss function v y f x displaystyle vyifx displaystyle ell norm regularization penalty min w r d n n v y w x w displaystyle min win mathbb r dfrac nsum invyilangle wxirangle lambda w x w r d displaystyle xwin mathbb rd w displaystyle w denote displaystyle ell norm define number nonzero entry vector w displaystyle w f x w x displaystyle fxlangle wxirangle say sparse w s d displaystyle wsd mean output y displaystyle y describe small subset input variablesmore generally assume dictionary j x r displaystyle phi jxrightarrow mathbb r j p displaystyle jp give target function f x displaystyle fx learning problem write f x j p j x w j displaystyle fxsum jpphi jxwj x x displaystyle forall xin x displaystyle ell norm f w displaystyle fw number nonzero component w displaystyle w define w j w j j p displaystyle wjwjneq jin p displaystyle cardinality set displaystyle f displaystyle f say sparse f w s d displaystyle fwsd displaystyle ell norm regularization favor sparse solution computationally difficult use additionally convex computationally feasible norm favor sparse solution displaystyle ell norm show favor sparse solution additionally convex structure sparsity regularization structure sparsity regularization extend generalize variable selection problem characterize sparsity regularization consider regularized empirical risk minimization problem general kernel associate feature map j x r displaystyle phi jxrightarrow mathbb r j p displaystyle jp min w r d n n v y w x w displaystyle min win mathbb r dfrac nsum invyilangle wphi xirangle lambda w regularization term w displaystyle lambda w penalize w j displaystyle wj component independently mean algorithm suppress input variable independently otherin situation want impose structure regularization process example input variable suppress accord predefin group structure sparsity regularization method allow impose structure add structure norm define regularization term structure norm nonoverlapp group group lasso nonoverlapping group case basic instance structure sparsity priori partition coefficient vector w displaystyle w g displaystyle g nonoverlapp group assume let w g displaystyle wg vector coefficient group g displaystyle g define regularization term group norm r w g g w g g displaystyle lambda rwlambda sum ggwgg w g g displaystyle wgg group displaystyle ell norm w g g j g g w g j displaystyle wggsqrt sum jggwgj g g displaystyle gg group g displaystyle g w g j displaystyle wgj jth component group g g displaystyle gg norm refer group lasso regularizer force entire coefficient group zero individual coefficient group nonoverlapp set nonzero coefficient obtain union group set zero conversely set zero coefficient overlap group overlap group structure sparsity case variable belong group g displaystyle g case interest represent general class relationship variable nonoverlapp group tree structure type graphsthere type overlap group sparsity regularization approach model different type input variable relationship intersection complement group lasso intersection complement approach case want select input variable positive coefficient group belong consider group lasso regularized empirical risk minimization problem r w g g w g g displaystyle lambda rwlambda sum ggwgg w g g displaystyle wgg group displaystyle ell norm g g displaystyle gg group g displaystyle g w g j displaystyle wgj jth component group g g displaystyle gg nonoverlapping group case group lasso regularizer potentially set entire group coefficient zero select variable coefficient w j displaystyle wj case group overlap intersection complement group set zerothis intersection complement selection criterion imply modeling choice allow coefficient particular group g displaystyle g set zero group g displaystyle g remain positive word coefficient group differ depend group membership variable group union group latent group lasso different approach consider union group variable selection approach capture modeling situation variable select long belong group positive coefficient modeling perspective imply want preserve group structurethe formulation union group approach refer latent group lasso require modify group displaystyle ell norm consider introduce follow regularizer r w n f g w g g w g g w g displaystyle rwinfleftsum gwggwsum ggbar wgright w r d displaystyle win mathbb rd w g g g displaystyle wgin gg vector coefficient group g w g r d displaystyle bar wgin mathbb rd vector coefficient w g j displaystyle wgj variable j displaystyle j group g displaystyle g displaystyle ie w g j w g j displaystyle bar wgjwgj j displaystyle j group g displaystyle g w g j displaystyle bar wgj otherwisethis regularizer interpret effectively replicate variable belong group conserve group structure intend union group approach require w g g w g displaystyle wsum ggbar wg produce vector weight w effectively sum weight variable group belong issue group lasso regularization alternative approach objective function group lasso consist error function generally require convex necessarily strongly convex group displaystyle ell regularization term issue objective function convex necessarily strongly convex generally lead unique solutionsan example way fix introduce square displaystyle ell norm weight vector additional regularization term keep displaystyle ell regularization term group lasso approach coefficient square displaystyle ell norm term great displaystyle square displaystyle ell norm term strongly convex result objective function strongly convex provide displaystyle ell coefficient suitably small positive weight vector minimize result objective function generally close weight vector minimize objective function result remove group displaystyle ell regularization term altogether original objective function scenario correspond group lasso approach approach allow simple optimization maintain sparsity norm base structure input variable submodular set functionbesid norm discuss norm structured sparsity method include hierarchical norm norm define grid norm arise submodular function allow incorporation prior assumption structure input variable context hierarchical norm structure represent direct acyclic graph variable context gridbas norm structure represent grid hierarchical norm unsupervised learningunsupervis learning method learn parameter latent variable model latent variable model statistical model addition observe variable set latent variable exist observe model hierarchy assume variable system system hierarchy represent direct acyclic graphshierarchie latent variable emerge natural structure application notably model text document hierarchical model bayesian nonparametric method learn topic model statistical model discover abstract topic occur collection document hierarchy consider context kernel method hierarchical norm apply bioinformatic computer vision topic model norm define grid structure assume variable form d d d grid submodular function base overlap group consider norm lead stable set equal rectangular convex shape method application computer vision algorithm computation good subset selection problem problem choose good subset input variable naturally formulate penalization framework min w r d n n v y w x w displaystyle min win mathbb r dfrac nsum invyiwxilambda w w displaystyle w denote displaystyle ell norm define number nonzero entry vector w displaystyle w formulation make sense modeling perspective computationally unfeasible equivalent exhaustive search evaluate possible subset variablestwo main approach solve optimization problem greedy method stepwise regression statistic match pursuit signal processing convex relaxation formulation approach proximal gradient optimization method convex relaxation natural approximation good subset selection problem displaystyle ell norm regularization min w r d n n v y w x w displaystyle min win mathbb r dfrac nsum invyiwxilambda w scheme call basis pursuit lasso substitute displaystyle ell norm convex nondifferentiable displaystyle ell norm proximal gradient method proximal gradient method call forwardbackward splitting optimization method useful minimize function convex differentiable component convex potentially nondifferentiable componentas proximal gradient method useful solve sparsity structure sparsity regularization problem follow form min w r d n n v y w x r w displaystyle min win mathbb r dfrac nsum invyiwxirw v y w x displaystyle vyiwxi convex differetiable loss function like quadratic loss r w displaystyle rw convex potentially nondifferentiable regularizer displaystyle ell norm connection area machine learn connection multiple kernel learn structure sparsity regularization apply context multiple kernel learn multiple kernel learning refer set machine learning method use predefined set kernel learn optimal linear nonlinear combination kernel algorithmin algorithm mention space take consideration partition group ie subspace complementary point view consider case distinct space combine obtain new useful discuss idea consider finite dictionary finite dictionary linearly independent element element know atom refer finite set linearly independent basis function linear combination define hypothesis space finite dictionary define specific kernel show assume example dictionary finite dictionary consideredfor simplicity case dictionary j x r j p displaystyle aajxrightarrow mathbb r jp b b t x r t q displaystyle bbtxrightarrow mathbb r tq q displaystyle q p displaystyle p integer consider atom displaystyle atom b displaystyle b assume linearly independent let d d k x r k p q b displaystyle ddkxrightarrow mathbb r kpqacup b union dictionary consider linear space function h displaystyle h give linear combination form f x p q w j d j x j p w j j x t q w b t b t x x x displaystyle fxsum ipqwjdjxsum jpwajajxsum tqwbtbtxxin x coefficient vector w r p w b r q displaystyle wain mathbb r pwbin mathbb r q w w w b displaystyle wwawb assume atom d displaystyle d linearly independent equivalently map w w w b f displaystyle wwawbmapsto f function space h displaystyle h see sum component space h displaystyle ha linear combination atom displaystyle h b displaystyle hb linear combination atom b displaystyle b choice norm space f w w b displaystyle fwawb note view h displaystyle h function space h displaystyle ha h b displaystyle hb subspace view linear independence assumption h displaystyle h identify r p q displaystyle mathbb r pq h h b displaystyle hahb r p r q displaystyle mathbb r pmathbb r q respectively norm mention see group norm h displaystyle h associate subspace h displaystyle ha h b displaystyle hb provide connection structured sparsity regularizationhere h displaystyle ha h b displaystyle hb h displaystyle h see reproducing kernel hilbert space corresponding feature map x r p displaystyle phi axrightarrow mathbb r p give x x p x displaystyle phi axaxapx b x r q displaystyle phi bxrightarrow mathbb r q give b x b x b q x displaystyle phi bxbxbqx x r p q displaystyle phi xrightarrow mathbb r pq give concatenation b displaystyle phi aphi b respectivelyin structured sparsity regularization approach scenario relevant group variable group norm consider correspond subspace h displaystyle ha h b displaystyle hb approach promote set group coefficient correspond subspace zero oppose individual coefficient promote sparse multiple kernel learningthe reasoning directly generalize finite number dictionary feature map extend feature map induce infinite dimensional hypothesisspace sparse multiple kernel learning useful consider sparse multiple kernel learning useful situation include follow datum fusion kernel correspond different kind modalityfeature nonlinear variable selection consider kernel k g displaystyle kg depend dimension inputgenerally sparse multiple kernel learning particularly useful kernel model selection interpretability important additional us application structured sparsity regularization method number setting desire impose priori input variable structure regularization process application arecompressive sense magnetic resonance imaging mri reconstruct mr image small number measurement potentially yield significant reduction mr scanning timerobust face recognition presence misalignment occlusion illumination variationuncover sociolinguistic association lexical frequency twitter author sociodemographic variable geographic communitiesgene selection analysis breast cancer datum prior overlap group eg biologically meaningful gene set statistical learning theoryregularizationsparse approximationproximal gradient methodsconvex analysisfeature selection reference'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_q_df['clean_content'].sample(2).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df= 2, max_df= .95, ngram_range=(1,2), stop_words= \"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=3, max_df=.9, stop_words = \"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix_sp = vectorizer.fit_transform(content_q_df.clean_content.str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix_sp_tf = tfidf_vectorizer.fit_transform(content_q_df.clean_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4115x188921 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1372199 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_sp_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 188921)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_sp_tf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4115x18873 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 736932 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 18873)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_sp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 400\n",
    "SVD = TruncatedSVD(n_components)\n",
    "components_names = [\"component_\"+str(i+1) for i in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis = SVD.fit_transform(doc_term_matrix_sp_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SVD.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00292268,  0.01368549,  0.00750553,  0.00537311,  0.00464621,\n",
       "        0.00384325,  0.0033631 ,  0.00320244,  0.0030688 ,  0.00281997,\n",
       "        0.00263468,  0.00250812,  0.0022863 ,  0.00215572,  0.00204309,\n",
       "        0.00193747,  0.00188146,  0.00184703,  0.0018066 ,  0.00175869,\n",
       "        0.00174151,  0.00172505,  0.00163545,  0.00160161,  0.00156387,\n",
       "        0.00154277,  0.00149312,  0.00146708,  0.00146421,  0.00144979,\n",
       "        0.00140365,  0.0013816 ,  0.00135882,  0.00133618,  0.00132423,\n",
       "        0.00129957,  0.00128273,  0.00126747,  0.00126013,  0.00124294,\n",
       "        0.00122619,  0.00120419,  0.00117867,  0.00117011,  0.00115653,\n",
       "        0.00115034,  0.00114819,  0.00113496,  0.00110529,  0.00108892,\n",
       "        0.00108016,  0.00106896,  0.00105858,  0.00105553,  0.00104858,\n",
       "        0.00104291,  0.00103089,  0.00102056,  0.00101725,  0.00100917,\n",
       "        0.00099667,  0.0009938 ,  0.00098406,  0.0009725 ,  0.00096583,\n",
       "        0.00096009,  0.00095704,  0.0009539 ,  0.000944  ,  0.00093276,\n",
       "        0.00093052,  0.00092826,  0.00091913,  0.00090664,  0.00090482,\n",
       "        0.0009005 ,  0.00089434,  0.00088809,  0.00088496,  0.00087253,\n",
       "        0.00086404,  0.00086046,  0.00086043,  0.0008556 ,  0.00085429,\n",
       "        0.00084822,  0.00084602,  0.00083555,  0.00083385,  0.00083054,\n",
       "        0.00082652,  0.00082237,  0.00081483,  0.00081369,  0.000809  ,\n",
       "        0.00080284,  0.00079471,  0.00079066,  0.00078894,  0.00078608,\n",
       "        0.0007802 ,  0.00077538,  0.00077163,  0.00076955,  0.00076404,\n",
       "        0.00076088,  0.0007583 ,  0.00075698,  0.00075084,  0.00074979,\n",
       "        0.00074366,  0.00074241,  0.00073843,  0.00073327,  0.00073088,\n",
       "        0.00072608,  0.0007232 ,  0.00072138,  0.00071774,  0.00071575,\n",
       "        0.00071274,  0.00071138,  0.00070831,  0.00070341,  0.00070227,\n",
       "        0.0006996 ,  0.00069734,  0.00069288,  0.0006919 ,  0.00069006,\n",
       "        0.00068658,  0.00068496,  0.0006817 ,  0.00067945,  0.0006742 ,\n",
       "        0.00067242,  0.00066852,  0.00066789,  0.00066615,  0.00066321,\n",
       "        0.0006624 ,  0.00065912,  0.00065671,  0.00065448,  0.00065212,\n",
       "        0.00064676,  0.00064604,  0.00064374,  0.00064177,  0.00064086,\n",
       "        0.00063799,  0.00063623,  0.00063593,  0.00063334,  0.00063142,\n",
       "        0.00062802,  0.00062685,  0.00062313,  0.0006224 ,  0.0006195 ,\n",
       "        0.00061741,  0.00061633,  0.00061427,  0.00061384,  0.00061065,\n",
       "        0.00060938,  0.00060864,  0.00060588,  0.00060414,  0.00060189,\n",
       "        0.00060143,  0.00060001,  0.00059658,  0.00059544,  0.00059418,\n",
       "        0.00059092,  0.00059072,  0.00058802,  0.00058758,  0.00058573,\n",
       "        0.0005841 ,  0.00058309,  0.00058211,  0.00057983,  0.00057784,\n",
       "        0.00057522,  0.00057416,  0.00057308,  0.00057198,  0.00057117,\n",
       "        0.00056952,  0.00056815,  0.00056695,  0.00056447,  0.00056426,\n",
       "        0.00056248,  0.00056108,  0.00055994,  0.00055727,  0.00055639,\n",
       "        0.00055533,  0.00055455,  0.00055191,  0.00055047,  0.00054988,\n",
       "        0.00054893,  0.00054802,  0.00054588,  0.00054557,  0.00054405,\n",
       "        0.0005421 ,  0.00054011,  0.00053839,  0.00053699,  0.00053593,\n",
       "        0.00053484,  0.00053298,  0.00053285,  0.00053184,  0.00053115,\n",
       "        0.00052971,  0.00052838,  0.00052752,  0.00052498,  0.00052402,\n",
       "        0.00052347,  0.00052192,  0.00052093,  0.00051947,  0.00051874,\n",
       "        0.0005183 ,  0.00051649,  0.00051506,  0.00051299,  0.00051245,\n",
       "        0.00051126,  0.00051001,  0.00050977,  0.00050892,  0.00050738,\n",
       "        0.00050644,  0.00050585,  0.00050521,  0.00050299,  0.00050218,\n",
       "        0.00050032,  0.00049871,  0.00049804,  0.00049762,  0.00049696,\n",
       "        0.00049615,  0.00049588,  0.00049452,  0.00049328,  0.00049248,\n",
       "        0.00049191,  0.00049077,  0.00048985,  0.00048851,  0.00048773,\n",
       "        0.00048691,  0.00048546,  0.0004844 ,  0.00048426,  0.00048301,\n",
       "        0.0004818 ,  0.00048104,  0.00047978,  0.00047879,  0.00047845,\n",
       "        0.00047773,  0.00047688,  0.00047596,  0.00047524,  0.00047427,\n",
       "        0.00047358,  0.00047252,  0.00047149,  0.0004709 ,  0.00046927,\n",
       "        0.00046867,  0.00046788,  0.00046638,  0.00046548,  0.00046508,\n",
       "        0.00046469,  0.00046288,  0.00046231,  0.00046137,  0.00046116,\n",
       "        0.00045943,  0.00045902,  0.00045763,  0.00045748,  0.00045639,\n",
       "        0.00045517,  0.00045451,  0.00045377,  0.00045249,  0.00045168,\n",
       "        0.00044964,  0.00044928,  0.00044871,  0.00044738,  0.00044658,\n",
       "        0.00044537,  0.00044442,  0.00044372,  0.00044275,  0.00044273,\n",
       "        0.00044212,  0.00044118,  0.00044005,  0.0004398 ,  0.0004387 ,\n",
       "        0.00043739,  0.00043667,  0.00043583,  0.0004348 ,  0.00043449,\n",
       "        0.00043348,  0.00043241,  0.0004319 ,  0.00043079,  0.00043028,\n",
       "        0.00042895,  0.00042797,  0.00042715,  0.00042661,  0.00042625,\n",
       "        0.00042571,  0.00042509,  0.00042446,  0.00042291,  0.00042236,\n",
       "        0.00042104,  0.0004203 ,  0.00041948,  0.00041875,  0.00041701,\n",
       "        0.00041685,  0.00041615,  0.00041443,  0.00041398,  0.00041315,\n",
       "        0.00041239,  0.00041214,  0.00041107,  0.00041048,  0.00040924,\n",
       "        0.00040802,  0.00040747,  0.000406  ,  0.00040569,  0.00040526,\n",
       "        0.000404  ,  0.00040351,  0.00040266,  0.00040196,  0.00040102,\n",
       "        0.00039997,  0.00039908,  0.00039853,  0.000398  ,  0.00039644,\n",
       "        0.00039624,  0.0003953 ,  0.000395  ,  0.00039316,  0.00039201,\n",
       "        0.00039135,  0.00038985,  0.00038943,  0.00038913,  0.00038859,\n",
       "        0.00038846,  0.00038679,  0.00038655,  0.00038532,  0.0003837 ,\n",
       "        0.00038338,  0.00038198,  0.0003815 ,  0.00038114,  0.00038044,\n",
       "        0.0003792 ,  0.00037772,  0.00037733,  0.00037677,  0.00037554,\n",
       "        0.00037409,  0.00037371,  0.00037289,  0.00037113,  0.00037057,\n",
       "        0.00036972,  0.00036889,  0.00036804,  0.00036645,  0.00036614])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# searching\n",
    "## cosine-similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_term = \"Neural Network\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_term_vec = tfidf_vectorizer.transform([search_term])\n",
    "search_term_lsa = SVD.transform(search_term_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarities = latent_semantic_analysis.dot(search_term_lsa.T).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3360, 3394, 3281, 3390, 3393])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities.argsort()[:-6:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snarc stochastic neural analog reinforcement calculator neural net machine design marvin lee minsky george miller gather funding project air force office scientific research summer time minskys graduate student princeton dean edmund volunteer good electronic minsky bring projectthe machine randomly connect network approximately hebb synaps synapse memory hold probability signal come input signal come output probability knob go show probability signal propagate probability signal get capacitor re\n"
     ]
    }
   ],
   "source": [
    "print(content_q_df.loc[3383]['clean_content'][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"neural\" in content_q_df.loc[3383]['clean_content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5 related articles and their catogories based on the search term¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic neural analog reinforcement calculator  :  Machine_Learning\n",
      "Gesture Description Language  :  Machine_Learning\n",
      "Helmholtz machine  :  Machine_Learning\n",
      "Causal Markov condition  :  Machine_Learning\n",
      "Reservoir computing  :  Machine_Learning\n",
      "Stochastic neural analog reinforcement calculator\n"
     ]
    }
   ],
   "source": [
    "top_5 = [3383, 3418, 3334, 3417, 3375]\n",
    "\n",
    "for n in top_5:\n",
    "    print( content_q_df.loc[n][\"title\"] , \" : \",content_q_df.loc[n][\"category\"])\n",
    "\n",
    "\n",
    "\n",
    "print(content_q_df.loc[3383][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stochastic neural analog reinforcement calculator', 'Gesture Description Language', 'Helmholtz machine', 'Causal Markov condition', 'Reservoir computing']\n"
     ]
    }
   ],
   "source": [
    "print([content_q_df.loc[n][\"title\"] for n in top_5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_term1 = \"customer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_term_vec1 = tfidf_vectorizer.transform([search_term1])\n",
    "search_term_lsa1 = SVD.transform(search_term_vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarities_1 = latent_semantic_analysis.dot(search_term_lsa1.T).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3039, 2496, 2493, 1803, 1176])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities_1.argsort()[:-6:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sap crm application integrate customer relationship management crm software manufacture sap se target business software requirement midsize large organization industry sector overview acquisition hybris sap gradually realign strategy crm solution space mainly take market leader salesforcecom cloud base solution bid competitive future focused sap shift cloud base crm solution traditional onpremise crmsap consolidate crm solution hybris brand customer engagement commerce sap offer variety solution\n"
     ]
    }
   ],
   "source": [
    "print(content_q_df.loc[2512]['clean_content'][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"customer\" in content_q_df.loc[2512]['clean_content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprenticeship learning  :  Machine_Learning\n",
      "SAP CRM  :  Business_Software\n",
      "User:Eli32167/sandbox  :  Business_Software\n",
      "FirstClass  :  Business_Software\n",
      "Marketing automation  :  Business_Software\n"
     ]
    }
   ],
   "source": [
    "top2_5 = [3064, 2512, 2509, 1812, 1182]\n",
    "\n",
    "for n in top2_5:\n",
    "    print( content_q_df.loc[n][\"title\"] , \" : \",content_q_df.loc[n][\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import NearestNeighbors\n",
    "#NN = NearestNeighbors()\n",
    "#NN.fit(latent_semantic_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_term_matrix_sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (188921, 400), indices imply (18873, 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4246\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[0;32m-> 4247\u001b[0;31m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m    108\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[0;32m--> 109\u001b[0;31m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 188921, placement implies 18873",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9970a363e7da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vocabulary_expression = pd.DataFrame(SVD.components_,\n\u001b[1;32m      2\u001b[0m                                      \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponents_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                      columns=vectorizer.get_feature_names()).T\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 297\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_possibly_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4254\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4255\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4256\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4231\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4232\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4233\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (188921, 400), indices imply (18873, 400)"
     ]
    }
   ],
   "source": [
    "vocabulary_expression = pd.DataFrame(SVD.components_,\n",
    "                                     index=components_names,\n",
    "                                     columns=vectorizer.get_feature_names()).T\n",
    "\n",
    "#IT SEEMS I DIDN'T PASSED THE CORRECT DATA SHAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-0c5a617209ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvocabulary_expression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_component_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_expression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary_expression' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    vocabulary_expression['abs_component_{}'.format(i)] = np.abs(vocabulary_expression['component_{}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a72316736d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary_expression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'component_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary_expression' is not defined"
     ]
    }
   ],
   "source": [
    "vocabulary_expression[['component_1']].sort_values('component_1',ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-43ef4012daf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary_expression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'component_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary_expression' is not defined"
     ]
    }
   ],
   "source": [
    "vocabulary_expression[['component_2']].sort_values('component_2',ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
